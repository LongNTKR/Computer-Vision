{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qbOHx2vOXtI-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "import math\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "u17LM282XvNf"
      },
      "outputs": [],
      "source": [
        "def load_data(path='/content/drive/MyDrive/Colab Notebooks/lemon_dataset', size=0.8):\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  lst_dir = os.listdir(path)\n",
        "\n",
        "  for dir in lst_dir:\n",
        "\n",
        "    new_path = path + '/' + dir\n",
        "\n",
        "    lst_img = os.listdir(new_path)\n",
        "\n",
        "    for img_name in lst_img:\n",
        "\n",
        "      x.append(np.asarray(Image.open(new_path + '/' + img_name)))\n",
        "\n",
        "    y += [lst_dir.index(dir)] * len(lst_img)\n",
        "  \n",
        "  n = len(x) // 3\n",
        "  m = int(n * 0.8)\n",
        "\n",
        "  x_train = x[: m] + x[n : n + m] + x[2 * n : 2 * n + m]\n",
        "  y_train = y[: m] + y[n : n + m] + y[2 * n : 2 * n + m]\n",
        "\n",
        "  x_test = x[m : n] + x[n + m : 2 * n] + x[2 * n + m:]\n",
        "  y_test = y[m : n] + y[n + m : 2 * n] + y[2 * n + m:]\n",
        "\n",
        "  return (x_train, y_train), (x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eQfoa-iDfHB2"
      },
      "outputs": [],
      "source": [
        "def adam(parameters, grads, v, s, t, learning_rate = 0.01, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
        "    \n",
        "    L = len(parameters) // 2                \n",
        "    v_corrected = {}                         \n",
        "    s_corrected = {}                         \n",
        "\n",
        "    for l in range(1, L + 1):\n",
        "\n",
        "        v[\"dW\" + str(l)] = beta1 * v[\"dW\" + str(l)] + (1 - beta1) * grads['dW' + str(l)]\n",
        "        v[\"db\" + str(l)] = beta1 * v[\"db\" + str(l)] + (1 - beta1) * grads['db' + str(l)]\n",
        "\n",
        "        v_corrected[\"dW\" + str(l)] = v[\"dW\" + str(l)] / (1 - np.power(beta1, t))\n",
        "        v_corrected[\"db\" + str(l)] = v[\"db\" + str(l)] / (1 - np.power(beta1, t))\n",
        "\n",
        "        s[\"dW\" + str(l)] = beta2 * s[\"dW\" + str(l)] + (1 - beta2) * np.power(grads['dW' + str(l)], 2)\n",
        "        s[\"db\" + str(l)] = beta2 * s[\"db\" + str(l)] + (1 - beta2) * np.power(grads['db' + str(l)], 2)\n",
        "\n",
        "        s_corrected[\"dW\" + str(l)] = s[\"dW\" + str(l)] / (1 - np.power(beta2, t))\n",
        "        s_corrected[\"db\" + str(l)] = s[\"db\" + str(l)] / (1 - np.power(beta2, t))\n",
        "\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * (v_corrected[\"dW\" + str(l)] / (np.sqrt(s_corrected[\"dW\" + str(l)]) + epsilon))\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * (v_corrected[\"db\" + str(l)] / (np.sqrt(s_corrected[\"db\" + str(l)]) + epsilon))\n",
        "\n",
        "    return parameters, v, s, v_corrected, s_corrected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "yDEe4f9JkSli"
      },
      "outputs": [],
      "source": [
        "def zero_pad(X, pad):\n",
        "\n",
        "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), mode='constant', constant_values = (0,0))\n",
        "    \n",
        "    return X_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "IhRR2IGvAQ4y"
      },
      "outputs": [],
      "source": [
        "def conv_backward(dZ, cache, lambd):\n",
        "\n",
        "    (A_prev, W, hparameters) = cache\n",
        "    \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) =  np.shape(A_prev)\n",
        "    \n",
        "    (f, f, n_C_prev, n_C) = np.shape(W)\n",
        "    \n",
        "    stride = hparameters['stride_conv']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    (m, n_H, n_W, n_C) = np.shape(dZ)\n",
        "    \n",
        "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                          \n",
        "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
        "    db = np.zeros((1, 1, 1, n_C))\n",
        "    \n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
        "    \n",
        "    for i in range(m):\n",
        "\n",
        "        a_prev_pad = A_prev_pad[i, :, :, :]\n",
        "        da_prev_pad = dA_prev_pad[i, :, :, :]\n",
        "\n",
        "        for h in range(n_H):\n",
        "\n",
        "            vert_start = stride * h\n",
        "            vert_end = stride * h + f\n",
        "\n",
        "            for w in range(n_W):\n",
        "\n",
        "                horiz_start = stride * w\n",
        "                horiz_end = stride * w + f\n",
        "\n",
        "                for c in range(n_C):\n",
        "\n",
        "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:, :, :, c] * dZ[i, h, w, c]\n",
        "                    dW[:, :, :, c] += a_slice * dZ[i, h, w, c]\n",
        "                    db[:, :, :, c] += dZ[i, h, w, c]\n",
        "                    \n",
        "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
        "\n",
        "    #dW += lambd/m * w\n",
        "    \n",
        "    return dA_prev, dW, db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "hHvcBjn05SUo"
      },
      "outputs": [],
      "source": [
        "def create_mask_from_window(x):\n",
        "\n",
        "    mask = (x == np.max(x))\n",
        "    \n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jqld0B_y5ScR"
      },
      "outputs": [],
      "source": [
        "def distribute_value(dz, shape):\n",
        "\n",
        "    (n_H, n_W) = shape\n",
        "    \n",
        "    average = np.prod(shape) \n",
        "    a = (dz/average)*np.ones(shape)\n",
        "\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "gZhcXFOY5O-J"
      },
      "outputs": [],
      "source": [
        "def pool_backward(dA, cache, mode = \"max\"):\n",
        "\n",
        "    (A_prev, hparameters) = cache\n",
        "    \n",
        "    stride = hparameters['stride_pool']\n",
        "    f = hparameters['f']\n",
        "    \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    (m , n_H, n_W, n_C) = dA.shape\n",
        "    \n",
        "    dA_prev = np.zeros(A_prev.shape)\n",
        "    \n",
        "    for i in range(m):\n",
        "\n",
        "        a_prev = A_prev[i, :, :, :]\n",
        "\n",
        "        for h in range(n_H):\n",
        "\n",
        "            vert_start = stride * h\n",
        "            vert_end = stride * h + f\n",
        "\n",
        "            for w in range(n_W):\n",
        "\n",
        "                horiz_start = stride * w\n",
        "                horiz_end = stride * w + f\n",
        "\n",
        "                for c in range(n_C):\n",
        "\n",
        "                    if mode == \"max\":\n",
        "\n",
        "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                        mask = create_mask_from_window(a_prev_slice)\n",
        "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += mask * dA[i, h, w, c]\n",
        "\n",
        "                    elif mode == \"average\":\n",
        "\n",
        "                        da = dA[i, h, w, c]\n",
        "                        shape = (f,f)\n",
        "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)\n",
        "    \n",
        "    return dA_prev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_propagation(X, Y, caches, hyparams, lambd):\n",
        "    \n",
        "    ((c_Z, c_A, c_W), (p_A), (h_A, h_W)) = caches\n",
        "\n",
        "    c_dZ = {}\n",
        "    c_dA = {}\n",
        "    c_dW = {}\n",
        "    c_db = {}\n",
        "\n",
        "    p_dA = {}\n",
        "\n",
        "    h_dZ = {}\n",
        "    h_dA = {}\n",
        "    h_dW = {}\n",
        "    h_db = {}\n",
        "  \n",
        "    m = X.shape[0]\n",
        "\n",
        "    h_L = len(h_A)\n",
        "    c_L = len(c_A)\n",
        "\n",
        "    for i in range(m):\n",
        "\n",
        "      h_A['A' + str(h_L)][i][Y[i]] -= 1\n",
        "\n",
        "    h_dZ['dZ' + str(h_L)] = h_A['A' + str(h_L)]\n",
        "    h_dW['dW' + str(h_L)] = 1. / m * np.dot(h_A['A' + str(h_L - 1)].T, h_dZ['dZ' + str(h_L)])# + lambd/m * h_W['W' + str(h_L)]\n",
        "    h_db['db' + str(h_L)] = 1. / m * np.sum(h_dZ['dZ' + str(h_L)], axis=0, keepdims=True)\n",
        "    \n",
        "    for l in range(h_L - 1, 1, -1):\n",
        "        \n",
        "        h_dA['dA' + str(l)] = np.dot(h_dZ['dZ' + str(l + 1)], h_W['W' + str(l + 1)].T)\n",
        "        h_dZ['dZ' + str(l)] = np.multiply(h_dA['dA' + str(l)], np.int64(h_A['A' + str(l)] > 0))\n",
        "        h_dW['dW' + str(l)] = 1. / m * np.dot(h_A['A' + str(l - 1)].T, h_dZ['dZ' + str(l)])# + lambd/m * h_W['W' + str(l)]\n",
        "        h_db['db' + str(l)] = 1. / m * np.sum(h_dZ['dZ' + str(l)], axis=0, keepdims=True)\n",
        "        \n",
        "    h_dA['dA1'] = np.dot(h_dZ['dZ2'], h_W['W2'].T)\n",
        "    h_dZ['dZ1'] = np.multiply(h_dA['dA1'], np.int64(h_A['A1'] > 0))\n",
        "    h_dW['dW1'] = 1. / m * np.dot(p_A['Afcl'].T, h_dZ['dZ1'])# + lambd/m * h_W['W1']\n",
        "    h_db['db1'] = 1. / m * np.sum(h_dZ['dZ1'], axis=0, keepdims=True)\n",
        "        \n",
        "    p_dA['dAfcl'] = np.dot(h_dZ['dZ1'], h_W['W1'].T)\n",
        "    p_dA['dA' + str(c_L)] = p_dA['dAfcl'].reshape(p_A['A' + str(c_L)].shape)\n",
        "    p_dA['dA' + str(c_L)] = pool_backward(p_dA['dA' + str(c_L)], (c_A['A' + str(c_L)], hyparams), mode = \"max\")\n",
        "    c_dA['dA' + str(c_L)] = np.multiply(p_dA['dA' + str(c_L)], np.int64(c_Z['Z' + str(c_L)] > 0))\n",
        "    c_dZ['dZ' + str(c_L)], c_dW['dW' + str(c_L)], c_db['db' + str(c_L)] = conv_backward(c_dA['dA' + str(c_L)], (p_A['A' + str(c_L - 1)], c_W['W' + str(c_L)], hyparams), lambd)\n",
        "\n",
        "    for l in range(c_L - 1, 1, -1):\n",
        "\n",
        "      p_dA['dA' + str(l)] = pool_backward(c_dZ['dZ' + str(l + 1)], (c_A['A' + str(l)], hyparams), mode = \"max\")\n",
        "      c_dA['dA' + str(l)] = np.multiply(p_dA['dA' + str(l)], np.int64(c_Z['Z' + str(l)] > 0))\n",
        "      c_dZ['dZ' + str(l)], c_dW['dW' + str(l)], c_db['db' + str(l)] = conv_backward(c_dA['dA' + str(l)], (p_A['A' + str(l - 1)], c_W['W' + str(l)], hyparams), lambd)\n",
        "\n",
        "    p_dA['dA1'] = pool_backward(c_dZ['dZ2'], (c_A['A1'], hyparams), mode = \"max\")\n",
        "    c_dA['dA1'] = np.multiply(p_dA['dA1'], np.int64(c_Z['Z1'] > 0))\n",
        "    c_dZ['dZ1'], c_dW['dW1'], c_db['db1'] = conv_backward(c_dA['dA1'], (X, c_W['W1'], hyparams), lambd)\n",
        "\n",
        "    c_grad = c_dW\n",
        "    c_grad.update(c_db)\n",
        "    h_grad = h_dW\n",
        "    h_grad.update(h_db)\n",
        "\n",
        "    return (c_grad, h_grad)"
      ],
      "metadata": {
        "id": "Ki-RX1hMPXeW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "7zTlt3EaPiht"
      },
      "outputs": [],
      "source": [
        "def regulizer(w):\n",
        "\n",
        "  regulizer = 0\n",
        "\n",
        "  for value in w.values():\n",
        "\n",
        "    regulizer += np.sum(np.square(value))\n",
        "\n",
        "  return regulizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "39rUrWrZPuzG"
      },
      "outputs": [],
      "source": [
        "def soft_max(z):\n",
        "  z = z - np.max(z, axis=1, keepdims=True)\n",
        "  z = np.exp(z)\n",
        "  return z / np.sum(z, axis=1, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "zi7tPDlfO8b1"
      },
      "outputs": [],
      "source": [
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride_pool\"]\n",
        "    \n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    for i in range(m):\n",
        "\n",
        "        for h in range(n_H):\n",
        "\n",
        "            vert_start = stride * h\n",
        "            vert_end = stride * h + f\n",
        "\n",
        "            for w in range(n_W):\n",
        "\n",
        "                horiz_start = stride * w\n",
        "                horiz_end = stride * w + f\n",
        "\n",
        "                for c in range(n_C):\n",
        "\n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "\n",
        "                    if mode == \"max\":\n",
        "\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "\n",
        "                    elif mode == \"average\":\n",
        "                      \n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    \n",
        "    return A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "izu4aBOkPu3y"
      },
      "outputs": [],
      "source": [
        "def relu(z):\n",
        "  return np.where(z > 0, z, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "CrAWL34YkwjK"
      },
      "outputs": [],
      "source": [
        "def conv_single_step(a_slice_prev, W, b):\n",
        "\n",
        "    s = np.multiply(a_slice_prev, W)\n",
        "    Z = np.sum(s)\n",
        "    Z = Z + float(b)\n",
        "\n",
        "    return Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "OBjrJMEjif-5"
      },
      "outputs": [],
      "source": [
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = np.shape(A_prev)\n",
        "    \n",
        "    (f, f, n_C_prev, n_C) = np.shape(W)\n",
        "    \n",
        "    stride = hparameters['stride_conv']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    n_H = int(((n_H_prev + 2*pad - f) / stride) + 1) \n",
        "    n_W = int(((n_W_prev + 2*pad - f) / stride) + 1) \n",
        "    \n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "    \n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    \n",
        "    for i in range(m):\n",
        "\n",
        "        for h in range(n_H):\n",
        "\n",
        "            vert_start = stride * h\n",
        "            vert_end = stride * h + f\n",
        "\n",
        "            for w in range(n_W):\n",
        "\n",
        "                horiz_start = stride * w\n",
        "                horiz_end = stride * w + f\n",
        "\n",
        "                for c in range(n_C):\n",
        "                  \n",
        "                    a_slice_prev = A_prev_pad[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[:, :, :, c], b[:, :, :, c])\n",
        "    \n",
        "    return Z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, Y, c_params, h_params, hyparams, lambd):\n",
        "\n",
        "  c_A = {}\n",
        "  c_W = {}\n",
        "  c_b = {}\n",
        "  c_Z = {}\n",
        "\n",
        "  p_A = {}\n",
        "\n",
        "  h_Z = {}\n",
        "  h_A = {}\n",
        "  h_W = {}\n",
        "  h_b = {}\n",
        "\n",
        "  c_L = len(c_params) // 2\n",
        "  m = X.shape[0]\n",
        "\n",
        "  for l in range(1, c_L + 1):\n",
        "    \n",
        "    c_W['W' + str(l)] = c_params['W' + str(l)]\n",
        "    c_b['b' + str(l)] = c_params['b' + str(l)]\n",
        "\n",
        "  h_L = len(h_params) // 2\n",
        "\n",
        "  for l in range(1, h_L + 1):\n",
        "  \n",
        "    h_W['W' + str(l)] = h_params['W' + str(l)]\n",
        "    h_b['b' + str(l)] = h_params['b' + str(l)]\n",
        "\n",
        "  c_Z['Z1'] = conv_forward(X, c_W['W1'], c_b['b1'], hyparams)\n",
        "  c_A['A1'] = relu(c_Z['Z1'])\n",
        "  p_A['A1'] = pool_forward(c_A['A1'], hyparams, mode = \"max\")\n",
        "\n",
        "  for l in range(2, c_L):\n",
        "\n",
        "    c_Z['Z' + str(l)] = conv_forward(p_A['A' + str(l - 1)], c_W['W' + str(l)], c_b['b' + str(l)], hyparams)\n",
        "    c_A['A' + str(l)] = relu(c_Z['Z' + str(l)])\n",
        "    p_A['A' + str(l)] = pool_forward(c_A['A' + str(l)], hyparams, mode = \"max\")\n",
        "\n",
        "\n",
        "  c_Z['Z' + str(c_L)] = conv_forward(p_A['A' + str(c_L - 1)], c_W['W' + str(c_L)], c_b['b' + str(c_L)], hyparams)\n",
        "  c_A['A' + str(c_L)] = relu(c_Z['Z' + str(c_L)])\n",
        "  p_A['A' + str(c_L)] = pool_forward(c_A['A' + str(c_L)], hyparams, mode = \"max\")\n",
        "\n",
        "  p_A['Afcl'] = p_A['A' + str(c_L)].reshape(m, -1)\n",
        "\n",
        "  h_Z['Z1'] = np.dot(p_A['Afcl'], h_W['W1']) + h_b['b1']\n",
        "  h_A['A1'] = relu(h_Z['Z1'])\n",
        "    \n",
        "  for l in range(2, h_L):\n",
        "      \n",
        "    h_Z['Z' + str(l)] = np.dot(h_A['A' + str(l - 1)], h_W['W' + str(l)]) + h_b['b' + str(l)]\n",
        "    h_A['A' + str(l)] = relu(h_Z['Z' + str(l)])\n",
        "    \n",
        "  h_Z['Z' + str(h_L)] = np.dot(h_A['A' + str(h_L - 1)], h_W['W' + str(h_L)]) + h_b['b' + str(h_L)]  \n",
        "  h_A['A' + str(h_L)] = soft_max(h_Z['Z' + str(h_L)])\n",
        "\n",
        "  log_probs = 0\n",
        "\n",
        "  for i in range(m):\n",
        "\n",
        "    log_probs += (-1) * np.log(h_A['A' + str(h_L)][i][Y[i]])\n",
        "\n",
        "  #regulize = regulizer(c_W) + regulizer(b_W) + regulizer(h_W) \n",
        "\n",
        "  cost = (1 / m) * log_probs# + regulize * lambd / (2 * m)\n",
        "  \n",
        "  return  cost, ((c_Z, c_A, c_W), (p_A), (h_A, h_W))"
      ],
      "metadata": {
        "id": "UxAZstIkOD4Q"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "UbnFy4s88WW-"
      },
      "outputs": [],
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 32):\n",
        "    \n",
        "    m = len(X)                 \n",
        "    mini_batches = []\n",
        "        \n",
        "    X = np.array(X, dtype='object')\n",
        "    Y = np.array(Y, dtype='object')\n",
        "\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[permutation].tolist()\n",
        "    shuffled_Y = Y[permutation].tolist()\n",
        "\n",
        "    inc = mini_batch_size\n",
        "\n",
        "    num_complete_minibatches = math.floor(m / mini_batch_size)\n",
        "    for k in range(num_complete_minibatches):\n",
        "        \n",
        "        mini_batch_X = shuffled_X[k * inc:(k + 1) * inc]\n",
        "        mini_batch_Y = shuffled_Y[k * inc:(k + 1) * inc]\n",
        "\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    if m % mini_batch_size != 0:\n",
        "\n",
        "        mini_batch_X = shuffled_X[(k + 1) * inc:]\n",
        "        mini_batch_Y = shuffled_Y[(k + 1) * inc:]\n",
        "        \n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "        \n",
        "        num_complete_minibatches += 1\n",
        "    \n",
        "    return num_complete_minibatches, mini_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "BkAWi70n9MVp"
      },
      "outputs": [],
      "source": [
        "def initialize_adam(parameters):\n",
        "    \n",
        "    L = len(parameters) // 2\n",
        "    v = {}\n",
        "    s = {}\n",
        "    \n",
        "    for l in range(1, L + 1):\n",
        "\n",
        "        v[\"dW\" + str(l)] = np.zeros(parameters['W' + str(l)].shape)\n",
        "        v[\"db\" + str(l)] = np.zeros(parameters['b' + str(l)].shape)\n",
        "        s[\"dW\" + str(l)] = np.zeros(parameters['W' + str(l)].shape)\n",
        "        s[\"db\" + str(l)] = np.zeros(parameters['b' + str(l)].shape)\n",
        "    \n",
        "    return v, s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "iCoOn8Na80Ch"
      },
      "outputs": [],
      "source": [
        "def c_initialize_parames(kernel_size, layers_dims, input_size):\n",
        "    \n",
        "    parameters = {}\n",
        "    n_H, n_W= input_size * 2, input_size * 2\n",
        "    L = len(layers_dims) - 1\n",
        "     \n",
        "    for l in range(1, L + 1):\n",
        "\n",
        "        n_H, n_W = n_H // 2, n_W // 2\n",
        "        parameters['W' + str(l)] = np.random.randn(kernel_size, kernel_size, layers_dims[l-1], layers_dims[l]) * np.sqrt(2./layers_dims[l-1])\n",
        "        parameters['b' + str(l)] = np.zeros((1, 1, 1, layers_dims[l]))\n",
        "        \n",
        "    return int((n_H / 2)  * (n_W / 2) * layers_dims[-1]), parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "PKCGxSAn8We2"
      },
      "outputs": [],
      "source": [
        "def h_initialize_params(layers_dims):\n",
        "    \n",
        "    parameters = {}\n",
        "    L = len(layers_dims) - 1\n",
        "     \n",
        "    for l in range(1, L + 1):\n",
        "\n",
        "        parameters['W' + str(l)] = np.random.randn(layers_dims[l-1], layers_dims[l]) * np.sqrt(2./layers_dims[l-1])\n",
        "        parameters['b' + str(l)] = np.zeros((1, layers_dims[l]))\n",
        "        \n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X, Y, c_layers_dims, h_layers_dims, kernel_size=(3, 3), input_size=(32, 32, 3), mini_batch_size = 32, hyparams = {\"pad\" : 1, \"stride_conv\": 1, \"f\" : 2, \"stride_pool\": 2},\n",
        "          learning_rate = 0.001, lambd = 0.0003, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 50, params = None):\n",
        "            \n",
        "    costs = []  \n",
        "    t = 0  \n",
        "    if params is None:\n",
        "\n",
        "      flatten, c_params = c_initialize_parames(kernel_size[0], [input_size[2]] + c_layers_dims, input_size[0])         \n",
        "      c_v, c_s = initialize_adam(c_params)\n",
        "\n",
        "      h_params = h_initialize_params([flatten] + h_layers_dims)         \n",
        "      h_v, h_s = initialize_adam(h_params)   \n",
        "\n",
        "    else:\n",
        "\n",
        "      c_params, h_params, _ = params\n",
        "\n",
        "      c_v, c_s = initialize_adam(c_params)\n",
        "      h_v, h_s = initialize_adam(h_params)\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        \n",
        "        m, minibatches = random_mini_batches(X, Y, mini_batch_size)\n",
        "        cost_total = 0\n",
        "        \n",
        "        start = timeit.default_timer()\n",
        "\n",
        "        for minibatch in minibatches:\n",
        "\n",
        "            (minibatch_X, minibatch_Y) = minibatch\n",
        "\n",
        "            minibatch_X = np.array(minibatch_X) / 255\n",
        "            minibatch_Y = np.array(minibatch_Y)\n",
        "\n",
        "            cost, caches = forward_propagation(minibatch_X, minibatch_Y, c_params, h_params, hyparams, lambd)\n",
        "\n",
        "            cost_total += cost\n",
        "            \n",
        "            grads = backward_propagation(minibatch_X, minibatch_Y, caches, hyparams, lambd)\n",
        "\n",
        "            t = t + 1 \n",
        "\n",
        "            c_params, c_v, c_s, _, _ = adam(c_params, grads[0], c_v, c_s, t, learning_rate, beta1, beta2,  epsilon)\n",
        "\n",
        "            h_params, h_v, h_s, _, _ = adam(h_params, grads[1], h_v, h_s, t, learning_rate, beta1, beta2,  epsilon)\n",
        "\n",
        "        cost_avg = cost_total / m\n",
        "        \n",
        "        end = timeit.default_timer()\n",
        "        print(f\"Epoch {i+1}/{num_epochs}: {end-start:.4f}\", end=\" \")\n",
        "        \n",
        "        print(f\"Cost: {cost_avg:.6f}\")\n",
        "        costs.append(cost_avg)\n",
        "\n",
        "    plt.plot(costs, label='loss', color='red')\n",
        "    plt.xlabel('epochs (per 1)')\n",
        "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return (c_params, h_params, hyparams)"
      ],
      "metadata": {
        "id": "iYIM3BD_O4sw"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, Y, parameters):\n",
        "\n",
        "  (c_params, h_params, hyparams) = parameters\n",
        "\n",
        "  c_A = {}\n",
        "  c_W = {}\n",
        "  c_b = {}\n",
        "  c_Z = {}\n",
        "\n",
        "  p_A = {}\n",
        "\n",
        "  h_Z = {}\n",
        "  h_A = {}\n",
        "  h_W = {}\n",
        "  h_b = {}\n",
        "\n",
        "  c_L = len(c_params) // 2\n",
        "  m = X.shape[0]\n",
        "\n",
        "  for l in range(1, c_L + 1):\n",
        "    \n",
        "    c_W['W' + str(l)] = c_params['W' + str(l)]\n",
        "    c_b['b' + str(l)] = c_params['b' + str(l)]\n",
        "\n",
        "  h_L = len(h_params) // 2\n",
        "\n",
        "  for l in range(1, h_L + 1):\n",
        "  \n",
        "    h_W['W' + str(l)] = h_params['W' + str(l)]\n",
        "    h_b['b' + str(l)] = h_params['b' + str(l)]\n",
        "\n",
        "  c_Z['Z1'] = conv_forward(X, c_W['W1'], c_b['b1'], hyparams)\n",
        "  c_A['A1'] = relu(c_Z['Z1'])\n",
        "  p_A['A1'] = pool_forward(c_A['A1'], hyparams, mode = \"max\")\n",
        "\n",
        "  for l in range(2, c_L):\n",
        "\n",
        "    c_Z['Z' + str(l)] = conv_forward(p_A['A' + str(l - 1)], c_W['W' + str(l)], c_b['b' + str(l)], hyparams)\n",
        "    c_A['A' + str(l)] = relu(c_Z['Z' + str(l)])\n",
        "    p_A['A' + str(l)] = pool_forward(c_A['A' + str(l)], hyparams, mode = \"max\")\n",
        "\n",
        "\n",
        "  c_Z['Z' + str(c_L)] = conv_forward(p_A['A' + str(c_L - 1)], c_W['W' + str(c_L)], c_b['b' + str(c_L)], hyparams)\n",
        "  c_A['A' + str(c_L)] = relu(c_Z['Z' + str(c_L)])\n",
        "  p_A['A' + str(c_L)] = pool_forward(c_A['A' + str(c_L)], hyparams, mode = \"max\")\n",
        "\n",
        "  p_A['Afcl'] = p_A['A' + str(c_L)].reshape(m, -1)\n",
        "\n",
        "  h_Z['Z1'] = np.dot(p_A['Afcl'], h_W['W1']) + h_b['b1']\n",
        "  h_A['A1'] = relu(h_Z['Z1'])\n",
        "    \n",
        "  for l in range(2, h_L):\n",
        "      \n",
        "    h_Z['Z' + str(l)] = np.dot(h_A['A' + str(l - 1)], h_W['W' + str(l)]) + h_b['b' + str(l)]\n",
        "    h_A['A' + str(l)] = relu(h_Z['Z' + str(l)])\n",
        "    \n",
        "  h_Z['Z' + str(h_L)] = np.dot(h_A['A' + str(h_L - 1)], h_W['W' + str(h_L)]) + h_b['b' + str(h_L)]  \n",
        "  h_A['A' + str(h_L)] = soft_max(h_Z['Z' + str(h_L)])\n",
        "\n",
        "  return  f\"Predict: {h_A['A' + str(h_L)].argmax()}, True: {y}\""
      ],
      "metadata": {
        "id": "xyfyGCQySN55"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gTUj5gyUdeFP"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train) , (x_test, y_test) = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-hjBo2zsdfPM"
      },
      "outputs": [],
      "source": [
        "c_layers_dims = [16, 32, 64, 128]\n",
        "h_layers_dims = [64, 32, 16, 8, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "F7HdqWKM4gjz",
        "outputId": "4d56ab79-9aac-47b4-915b-f8d6ee09ec83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5: 133.5787 Cost: 0.043234\n",
            "Epoch 2/5: 134.4512 Cost: 0.032261\n",
            "Epoch 3/5: 133.5569 Cost: 0.024911\n",
            "Epoch 4/5: 134.9584 Cost: 0.018385\n",
            "Epoch 5/5: 135.6099 Cost: 0.017653\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "parameters = model(x_train, y_train, c_layers_dims, h_layers_dims, mini_batch_size=4, num_epochs=5, learning_rate=0.0001, params=parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfJAVtu6Hn6S",
        "outputId": "f211ca2c-0cce-4b5a-b9c0-0c49a455a6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 0, True: 0\n",
            "Predict: 2, True: 1\n",
            "Predict: 1, True: 1\n",
            "Predict: 1, True: 1\n",
            "Predict: 2, True: 1\n",
            "Predict: 1, True: 1\n",
            "Predict: 1, True: 1\n",
            "Predict: 2, True: 1\n",
            "Predict: 2, True: 1\n",
            "Predict: 1, True: 1\n",
            "Predict: 1, True: 1\n",
            "Predict: 1, True: 1\n",
            "Predict: 2, True: 2\n",
            "Predict: 2, True: 2\n",
            "Predict: 2, True: 2\n",
            "Predict: 2, True: 2\n",
            "Predict: 1, True: 2\n",
            "Predict: 2, True: 2\n",
            "Predict: 2, True: 2\n",
            "Predict: 2, True: 2\n",
            "Predict: 2, True: 2\n",
            "Predict: 1, True: 2\n",
            "Predict: 2, True: 2\n",
            "Predict: 2, True: 2\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(x_test)):\n",
        "  x = np.asarray(x_test[i]).reshape(1, 32, 32, 3) / 255\n",
        "  y = np.asarray(y_test[i])\n",
        "  print(predict(x, y, parameters))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}